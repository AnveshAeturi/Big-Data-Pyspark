# Big-Data-Pyspark
#### Simple ETL solutions using Pyspark and Spark-SQL.
1. Iris-ETL
2. Load Strategy Overwrite
3. ETL pipeline flows like:
   - Read the CSV file and check the Data Quality
   - Write it to simple CSV and partioned Parquet/CSV file
4.Input:
Id	SepalLengthCm	SepalWidthCm	PetalLengthCm	PetalWidthCm	Species
1	5.1	3.5	1.4	0.2	Iris-setosa
2	4.9	3	1.4	0.2	Iris-setosa
3	4.7	3.2	1.3	0.2	Iris-setosa
4	4.6	3.1	1.5	0.2	Iris-setosa
![image](https://user-images.githubusercontent.com/26872900/162202599-8590a42c-ae32-4788-82d6-8951ae4fa077.png)
